{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"xlaq2LMzzGMJ"},"source":["### MNIST: Classifying Handwritten Digits\n","This project uses Tensorflow and Keras to classify handwritten digits"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wHKUUZxLzGMO"},"outputs":[],"source":["## Import needed libraries & modules\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.datasets import mnist"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5L74DeeKzGMQ"},"source":["##### Load the Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Uakb6IpizGMQ"},"outputs":[],"source":["(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5hYSorVEzGMR"},"source":["##### Justify your preprocessing"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"unYoiX0EzGMR"},"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yPQuWRl4zGMS"},"source":["##### Explore the Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"NKaGRNo04yKP"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([60000    28    28], shape=(3,), dtype=int32)\n"]},{"name":"stderr","output_type":"stream","text":["2023-09-13 06:26:33.145741: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n","2023-09-13 06:26:33.145776: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n","2023-09-13 06:26:33.145786: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n","2023-09-13 06:26:33.146468: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2023-09-13 06:26:33.146837: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]}],"source":["print(tf.shape(X_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IPoatI1KzGMS"},"outputs":[],"source":["## This cell contains a function for showing 5 images from a dataloader â€“ DO NOT CHANGE THE CONTENTS! ##\n","def show5(img_loader):\n","    dataiter = iter(img_loader)\n","\n","    batch = next(dataiter)\n","    labels = batch[1][0:5]\n","    images = batch[0][0:5]\n","    for i in range(5):\n","        print(int(labels[i].detach()))\n","\n","        image = images[i].numpy()\n","        plt.imshow(image.T.squeeze().T)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pl1LTry_zGMS"},"outputs":[],"source":["# Explore data\n","show5(train_loader)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YNSs-ARQzGMT"},"source":["## Build your Neural Network\n","Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n","Use any architecture you like.\n","\n","*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJJqwNSTzGMT"},"outputs":[],"source":["# Define the class for your neural network\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.activation = F.relu\n","        self.layer1 = nn.Linear(28 * 28 * 1, 128)\n","        self.layer2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        x = self.activation(self.layer1(x))\n","        x = self.layer2(x)\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Q_W9ycdezGMT"},"source":["Specify a loss function and an optimizer, and instantiate the model.\n","\n","If you use a less common loss function, please note why you chose that loss function in a comment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCFnbxsmzGMT"},"outputs":[],"source":["# Instantiate the model\n","net = Net()\n","\n","# Choose an optimizer\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","# Choose a loss function\n","criterion = nn.CrossEntropyLoss()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LcIhMOkgzGMU"},"source":["## Running your Neural Network\n","Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch.\n","Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n","\n","If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lLnpmFLB-k1q"},"outputs":[],"source":["num_epochs = 10\n","\n","# Establish a list for our history\n","train_loss_history = list()\n","\n","for epoch in range(num_epochs):\n","    net.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    for i, data in enumerate(train_loader):\n","        # data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # Pass to GPU if available.\n","        if torch.cuda.is_available():\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Zero out the gradients of the optimizer\n","        optimizer.zero_grad()\n","\n","        # Get the outputs of your model and compute your loss\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Compute the loss gradient using the backward method and have the optimizer take a step\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Compute the accuracy and print the accuracy and loss\n","        _, preds = torch.max(outputs.data, 1)\n","        train_correct += (preds == labels).sum().item()\n","        train_loss += loss.item()\n","    print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n","    train_loss_history.append(train_loss/len(train_loader))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3nGbGqwWzGMU"},"source":["Plot the training loss (and validation loss/accuracy, if recorded)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5lJ5tAZw3hEl"},"outputs":[],"source":["# Plot the training and validation loss history\n","plt.plot(train_loss_history, label=\"Training Loss\")\n","plt.legend()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JIIACXfSzGMV"},"source":["## Testing your model\n","Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction.\n","\n","If your accuracy is over 90%, great work, but see if you can push a bit further!\n","If your accuracy is under 90%, you'll need to make improvements.\n","Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wb80ESBr4wIz"},"outputs":[],"source":["val_correct = 0\n","net.eval()\n","for inputs, labels in test_loader:\n","  if torch.cuda.is_available():\n","    inputs, labels = inputs.cuda(), labels.cuda()\n","\n","  outputs = net(inputs)\n","  loss = criterion(outputs, labels)\n","\n","  _, preds = torch.max(outputs.data, 1)\n","  val_correct += (preds == labels).sum().item()\n","print(f'Percentage of Correct Predictions: {val_correct/len(test_loader):.2f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6cflXKLpzGMV"},"source":["## Improving your model\n","\n","Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4QML-R6qq5IH"},"source":["The model above is the most accurate. I tried a number of variations on the layers, activation functions, step size, and optimizers and until I happened upon the above model my accuract was more like 8-9%"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MXcCYA87zGMW"},"source":["## Saving your model\n","Using `torch.save`, save your model for future loading."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRN4YsF2zGMW"},"outputs":[],"source":["save_path = '/net.pt'\n","torch.save(net.state_dict(), save_path)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
